{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Alexnet model"
      ],
      "metadata": {
        "id": "Gkr1ZFsCuHG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# This is the code for the Alexnet where the weights of the model are not trained\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#Hyper_parameters\n",
        "num_epochs = 2\n",
        "learning_rate = 0.001\n",
        "bs = 100\n",
        "\n",
        "# Define the CNN model\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.layer1 = nn.Conv2d(3, 96, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.layer2 = nn.Conv2d(96, 256, kernel_size=3, padding= 'same')\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.layer3 = nn.Conv2d(256, 384, kernel_size=3, padding= 'same')\n",
        "        self.relu3 = nn.ReLU()\n",
        "\n",
        "        self.layer4 = nn.Conv2d(384, 384, kernel_size=3, padding= 'same')\n",
        "        self.relu4 = nn.ReLU()\n",
        "\n",
        "        self.layer5 = nn.Conv2d(384, 256, kernel_size=3, padding= 'same')\n",
        "        self.relu5 = nn.ReLU()\n",
        "        self.pool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        # Calculate the input size for the fully connected layer\n",
        "        self.fc1_input_size = 6*6*256\n",
        "        self.fc1 = nn.Linear(self.fc1_input_size, 4096)\n",
        "        self.relu3 = nn.ReLU()\n",
        "\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.relu4 = nn.ReLU()\n",
        "\n",
        "        self.fc3 = nn.Linear(4096, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.relu1(self.layer1(x)))\n",
        "        x = self.pool2(self.relu2(self.layer2(x)))\n",
        "        x = self.relu3(self.layer3(x))\n",
        "        x = self.relu4(self.layer4(x))\n",
        "        x = self.pool5(self.relu5(self.layer5(x)))\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), 256 * 6 * 6)\n",
        "        x = self.flatten(x)\n",
        "        x = self.relu3(self.fc1(x))\n",
        "        x = self.relu4(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# CIFAR10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size = bs, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size = bs, shuffle=False)\n",
        "\n",
        "# Create the model, loss function, and optimizer\n",
        "model = CNNModel().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "# Training the model\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False)\n",
        "    for images, labels in progress_bar:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        progress_bar.set_postfix({'Loss': loss.item()}, refresh=True)\n",
        "\n",
        "    progress_bar.close()\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "class_correct = torch.zeros(10)\n",
        "class_total = torch.zeros(10)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        total_predictions += labels.size(0)\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(10):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "# Print class-wise accuracy\n",
        "for i in range(10):\n",
        "    accuracy = (class_correct[i] / class_total[i]) * 100 if class_total[i] != 0 else 0\n",
        "    print(f\"Class {i} Accuracy: {accuracy}%\")\n",
        "\n",
        "# Print overall accuracy\n",
        "overall_accuracy = (correct_predictions / total_predictions) * 100\n",
        "print(f\"Overall Test Accuracy: {overall_accuracy}%\")"
      ],
      "metadata": {
        "id": "uHgyDckcCX8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resnet model"
      ],
      "metadata": {
        "id": "5T4vkEjluLkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# This is the code for a Resnet model which is not trained\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#Hyper_parameters\n",
        "num_epochs = 2\n",
        "learning_rate = 0.001\n",
        "bs = 100\n",
        "\n",
        "# Define the basic residual block\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # Shortcut connection for identity mapping when the input and output dimensions are the same\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.shortcut(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x += residual  # Add the shortcut connection\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "# Define the ResNet architecture\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 16\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(64, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride))\n",
        "        self.in_channels = out_channels\n",
        "        for _ in range(1, num_blocks):\n",
        "            layers.append(block(out_channels, out_channels, stride=1))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# CIFAR10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size = bs, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size = bs, shuffle=False)\n",
        "\n",
        "# Create the model, loss function, and optimizer\n",
        "model = ResNet(ResidualBlock, [2, 2, 2])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "# Training the model\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False)\n",
        "    for images, labels in progress_bar:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        progress_bar.set_postfix({'Loss': loss.item()}, refresh=True)\n",
        "\n",
        "    progress_bar.close()\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "class_correct = torch.zeros(10)\n",
        "class_total = torch.zeros(10)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        total_predictions += labels.size(0)\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(10):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "# Class-wise accuracy\n",
        "for i in range(10):\n",
        "    accuracy = (class_correct[i] / class_total[i]) * 100 if class_total[i] != 0 else 0\n",
        "    print(f\"Class {i} Accuracy: {accuracy}%\")\n",
        "\n",
        "# Overall accuracy\n",
        "overall_accuracy = (correct_predictions / total_predictions) * 100\n",
        "print(f\"Overall Test Accuracy: {overall_accuracy}%\")\n"
      ],
      "metadata": {
        "id": "JZ8FP2AoDgJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, to compare the results of the above 2 models, employ the below code, which will demonstrate the training and test accuracies of the model."
      ],
      "metadata": {
        "id": "spJuoZuCqOGJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "#Device Configuration\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "num_epochs = 5\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Lists to store accuracy values during training and evaluation\n",
        "alexnet_train_accuracy = []\n",
        "resnet_train_accuracy = []\n",
        "alexnet_test_accuracy = []\n",
        "resnet_test_accuracy = []\n",
        "\n",
        "# Function to train the model\n",
        "def train_model(model, criterion, optimizer, scheduler, train_accuracy_list, num_epochs):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False)\n",
        "        for inputs, labels in progress_bar:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Track training accuracy\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct_predictions += (preds == labels).sum().item()\n",
        "            total_predictions += labels.size(0)\n",
        "\n",
        "        train_accuracy = correct_predictions / total_predictions\n",
        "        train_accuracy_list.append(train_accuracy)\n",
        "        progress_bar.close()\n",
        "\n",
        "        # Evaluation on the validation set\n",
        "        model.eval()\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                correct_predictions += (preds == labels).sum().item()\n",
        "                total_predictions += labels.size(0)\n",
        "\n",
        "        test_accuracy = correct_predictions / total_predictions\n",
        "        scheduler.step()\n",
        "\n",
        "        if isinstance(model, AlexNet):\n",
        "            alexnet_test_accuracy.append(test_accuracy)\n",
        "        elif isinstance(model, ResNet):\n",
        "            resnet_test_accuracy.append(test_accuracy)\n",
        "\n",
        "# Model implementation (AlexNet)\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.layer1 = nn.Conv2d(3, 96, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.layer2 = nn.Conv2d(96, 256, kernel_size=3, padding= 'same')\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.layer3 = nn.Conv2d(256, 384, kernel_size=3, padding= 'same')\n",
        "        self.relu3 = nn.ReLU()\n",
        "\n",
        "        self.layer4 = nn.Conv2d(384, 384, kernel_size=3, padding= 'same')\n",
        "        self.relu4 = nn.ReLU()\n",
        "\n",
        "        self.layer5 = nn.Conv2d(384, 256, kernel_size=3, padding= 'same')\n",
        "        self.relu5 = nn.ReLU()\n",
        "        self.pool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        # Calculating the input size for the fully connected layer\n",
        "        self.fc1_input_size = 6*6*256\n",
        "        self.fc1 = nn.Linear(self.fc1_input_size, 4096)\n",
        "        self.relu3 = nn.ReLU()\n",
        "\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.relu4 = nn.ReLU()\n",
        "\n",
        "        self.fc3 = nn.Linear(4096, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.relu1(self.layer1(x)))\n",
        "        x = self.pool2(self.relu2(self.layer2(x)))\n",
        "        x = self.relu3(self.layer3(x))\n",
        "        x = self.relu4(self.layer4(x))\n",
        "        x = self.pool5(self.relu5(self.layer5(x)))\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), 256 * 6 * 6)\n",
        "        x = self.flatten(x)\n",
        "        x = self.relu3(self.fc1(x))\n",
        "        x = self.relu4(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Model implementation (ResNet)\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # Shortcut connection for identity mapping when the input and output dimensions are the same\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.shortcut(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x += residual  # Add the shortcut connection\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "# Define the ResNet architecture\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 16\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(64, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride))\n",
        "        self.in_channels = out_channels\n",
        "        for _ in range(1, num_blocks):\n",
        "            layers.append(block(out_channels, out_channels, stride=1))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the models\n",
        "alexnet_model = AlexNet().to(device)\n",
        "model = ResNet(ResidualBlock, [2, 2, 2])\n",
        "resnet_model = model.to(device)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "alexnet_optimizer = optim.Adam(alexnet_model.parameters(), lr=learning_rate)\n",
        "resnet_optimizer = optim.Adam(resnet_model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Learning rate scheduler\n",
        "alexnet_scheduler = lr_scheduler.StepLR(alexnet_optimizer, step_size=5, gamma=0.1)\n",
        "resnet_scheduler = lr_scheduler.StepLR(resnet_optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "# Train the models\n",
        "train_model(alexnet_model, criterion, alexnet_optimizer, alexnet_scheduler, alexnet_train_accuracy, num_epochs)\n",
        "train_model(resnet_model, criterion, resnet_optimizer, resnet_scheduler, resnet_train_accuracy, num_epochs)\n",
        "\n",
        "# Plot the training and test accuracy curves\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# AlexNet\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, num_epochs + 1), alexnet_train_accuracy, label='Train Accuracy')\n",
        "plt.plot(range(1, num_epochs + 1), alexnet_test_accuracy, label='Test Accuracy')\n",
        "plt.title('AlexNet Training and Test Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# ResNet\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, num_epochs + 1), resnet_train_accuracy, label='Train Accuracy')\n",
        "plt.plot(range(1, num_epochs + 1), resnet_test_accuracy, label='Test Accuracy')\n",
        "plt.title('ResNet Training and Test Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TmPfVAVLq51l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below one is the code for simulating a pre trained Alexnet architecture"
      ],
      "metadata": {
        "id": "u-bn_wfNrhtV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the code for simulating a pre trained Alexnet architecture\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torchinfo import summary\n",
        "from tqdm import tqdm\n",
        "\n",
        "#Hyper_parameters\n",
        "num_epochs = 2\n",
        "bs = 32  #Batch size\n",
        "learning_rate = 0.001\n",
        "\n",
        "#Device Configuration\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "#Data transformations for CIFAR10\n",
        "transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "weights = models.AlexNet_Weights.DEFAULT\n",
        "weights.transforms()\n",
        "\n",
        "#CIFAR10 dataset and dataloaders\n",
        "training_dataset = datasets.CIFAR10('./data_src', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10('./data_src', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(training_dataset, batch_size=bs, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=bs, shuffle=False, drop_last=True)\n",
        "\n",
        "#Loading the pretrained AlexNet Model\n",
        "AlexneT = models.alexnet(weights=models.AlexNet_Weights.IMAGENET1K_V1)\n",
        "model = AlexneT.to(device)\n",
        "summary(model, input_size=(32, 3, 224, 224))\n",
        "\n",
        "# Here, as the dataset taken has 10 classes, so the model should also be calebrited accourdingly. For this, last set of fully connected layers are modified to give the output in 10.\n",
        "modified_AlexNet = models.alexnet(weights=models.AlexNet_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# As we only need to train the last layer for the modifications, thus, freezing rest of the layers.\n",
        "for param in modified_AlexNet.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Modifications applied\n",
        "modified_AlexNet.avgpool = nn.AdaptiveAvgPool2d(output_size=(2, 2))\n",
        "modified_AlexNet.classifier = nn.Sequential()\n",
        "modified_AlexNet.classifier.add_module('dropout1', nn.Dropout(p=0.5))\n",
        "modified_AlexNet.classifier.add_module('linear1', nn.Linear(in_features=1024, out_features=512))\n",
        "modified_AlexNet.classifier.add_module('relu1', nn.ReLU(inplace=True))\n",
        "modified_AlexNet.classifier.add_module('dropout2', nn.Dropout(p=0.5))\n",
        "modified_AlexNet.classifier.add_module('linear2', nn.Linear(in_features=512, out_features=512))\n",
        "modified_AlexNet.classifier.add_module('relu2', nn.ReLU(inplace=True))\n",
        "modified_AlexNet.classifier.add_module('dropout3', nn.Dropout(p=0.5))\n",
        "modified_AlexNet.classifier.add_module('linear3', nn.Linear(in_features=512, out_features=10)) #Output features changed from 1000 to 10.\n",
        "\n",
        "# Summary of the modified model\n",
        "model_to_train = modified_AlexNet.to(device)\n",
        "summary(model_to_train, input_size=(32, 3, 224, 224))\n",
        "\n",
        "# Loss and optimizer functions\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_to_train.parameters(), lr= learning_rate)\n",
        "\n",
        "# Training the model\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False)\n",
        "    for images, labels in progress_bar:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_to_train(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        progress_bar.set_postfix({'Loss': loss.item()}, refresh=True)\n",
        "\n",
        "    progress_bar.close()\n",
        "\n",
        "# Evaluation\n",
        "model_to_train.eval()\n",
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "class_correct = torch.zeros(10)\n",
        "class_total = torch.zeros(10)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model_to_train(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        total_predictions += labels.size(0)\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(10):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "# Class wise accuracy\n",
        "for i in range(10):\n",
        "    accuracy = (class_correct[i] / class_total[i]) * 100 if class_total[i] != 0 else 0\n",
        "    print(f\"Class {i} Accuracy: {accuracy}%\")\n",
        "\n",
        "# Overall accuray of the model\n",
        "overall_accuracy = (correct_predictions / total_predictions) * 100\n",
        "print(f\"Overall Test Accuracy: {overall_accuracy}%\")\n"
      ],
      "metadata": {
        "id": "yfufxuegHA98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below one is the code for the simulation of a pre-trained Resnet architiecture\n"
      ],
      "metadata": {
        "id": "t9FUVeH1r3uO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# This is the code for the simulation of a pretrained Resnet architiecture\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torchinfo import summary\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#Hyper_parameters\n",
        "num_epochs = 2\n",
        "learning_rate = 0.001\n",
        "bs = 32\n",
        "\n",
        "# CIFAR10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size = bs, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size = bs, shuffle=False)\n",
        "\n",
        "# Loading the pretrained ResNet18 architecture\n",
        "ResNet = models.resnet18(pretrained = True)\n",
        "model = ResNet.to(device)\n",
        "summary(model, input_size=(32, 3, 32, 32))\n",
        "\n",
        "# Here, as the dataset taken has 10 classes, so the model should also be calebrited accourdingly. For this, last set of fully connected layers are modified to give the output in 10.\n",
        "modified_model = models.resnet18(pretrained = True)\n",
        "\n",
        "# As we only need to train the last layer for the modifications, thus, freezing rest of the layers.\n",
        "for param in modified_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Modifications\n",
        "modified_fc = nn.Linear(in_features=512, out_features=10, bias=True)\n",
        "modified_model.fc = modified_fc\n",
        "\n",
        "# Summary of the modified model\n",
        "model_to_train = modified_model.to(device)\n",
        "summary(model_to_train, input_size=(32, 3, 32, 32))\n",
        "\n",
        "# Loss and optimizer functions\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_to_train.parameters(), lr=0.001)\n",
        "\n",
        "# Training the model\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False)\n",
        "    for images, labels in progress_bar:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_to_train(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        progress_bar.set_postfix({'Loss': loss.item()}, refresh=True)\n",
        "\n",
        "    progress_bar.close()\n",
        "\n",
        "# Evaluation\n",
        "model_to_train.eval()\n",
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "class_correct = torch.zeros(10)\n",
        "class_total = torch.zeros(10)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model_to_train(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        total_predictions += labels.size(0)\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(10):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "# Class-wise accuracy\n",
        "for i in range(10):\n",
        "    accuracy = (class_correct[i] / class_total[i]) * 100 if class_total[i] != 0 else 0\n",
        "    print(f\"Class {i} Accuracy: {accuracy}%\")\n",
        "\n",
        "# Overall accuracy of the model\n",
        "overall_accuracy = (correct_predictions / total_predictions) * 100\n",
        "print(f\"Overall Test Accuracy: {overall_accuracy}%\")\n"
      ],
      "metadata": {
        "id": "C8CvBsTCHBHh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}